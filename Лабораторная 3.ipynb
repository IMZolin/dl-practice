{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHJJv6Doqxdi"
   },
   "source": [
    "В задании вам понадобится собрать генеративную модлель для языка\n",
    "\n",
    "---\n",
    "\n",
    "# LSTM (7 баллов)\n",
    "\n",
    "В данной части нужно реализовать модель с ипользованием LSTM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PApXEiq7p6sN",
    "outputId": "46b92ce1-ba99-4cb3-8b42-4b80a84ada88",
    "ExecuteTime": {
     "end_time": "2024-10-15T07:09:40.275873Z",
     "start_time": "2024-10-15T07:09:39.257816Z"
    }
   },
   "source": [
    "!pip install --quiet sentencepiece datasets transformers"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VyyvGpTQp6sO",
    "ExecuteTime": {
     "end_time": "2024-10-15T07:09:43.889295Z",
     "start_time": "2024-10-15T07:09:42.777764Z"
    }
   },
   "source": [
    "import random\n",
    "import torch \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKyLiCWrp6sO"
   },
   "outputs": [],
   "source": [
    "# Добавьте код для подготовки данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZgQRhlJ4zlC",
    "outputId": "384d8384-9bbb-430f-91d0-72889b9e5b24",
    "ExecuteTime": {
     "end_time": "2024-10-15T07:10:01.962067Z",
     "start_time": "2024-10-15T07:10:01.956812Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW_QSr1NsqrJ"
   },
   "source": [
    "Ниже вам нужно реализовать модель, которая по началу последовательности предсказывает следующий токен.\n",
    "*   Модель получает на вход последовательность токенов, прогоняет её через LSTM и выдает вероятности следующего токена.  \n",
    "*   Используйте LSTM из pytorch\n",
    "*   Не забудьте про `batch_first`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgF5jttMql7e"
   },
   "outputs": [],
   "source": [
    "class RnnGenerator(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token_idx)\n",
    "        self.lstm = torch.nn.LSTM(embed_dim, embed_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "\n",
    "    #x: (batch_size, seq_len)\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izp-AJ-RDtJ9",
    "outputId": "4a6f531f-37d5-46e2-a34d-f055806fc2e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIp_w8_HqzkK"
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "model = RnnGenerator(vocab_size, 512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-peSCz_NhE7",
    "outputId": "d6134dd4-8e61-4f15-d840-7ddffe47d7eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 8000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "model(batch[:, :-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6APRvLD1MW-"
   },
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V8oy5i-rSe2"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Alhboqx4emr"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = pad_token_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOzmA6e1d2uO"
   },
   "source": [
    "Реализуйте обучение модели:\n",
    "*  Не забудьте сдвинуть src и trg относительно друг друга.\n",
    "*  Не забудьте про `clip_grad_norm_`\n",
    "*  Данных очень много, для отладки лучше проходить только часть данных иначе этоха будет очень длинной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc60fcsTuJKj"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, callback):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    n_inter = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        src = batch[:, :-1].to(device)  # Входная последовательность\n",
    "        trg = batch[:, 1:].to(device)   # Последовательность целей (сдвинутая)\n",
    "        \n",
    "        optimizer.zero_grad()  # Обнуляем градиенты\n",
    "\n",
    "        # Прогоняем через модель\n",
    "        logits = model(src)\n",
    "\n",
    "        # Вычисляем функцию потерь\n",
    "        loss = criterion(logits.transpose(1, 2), trg)\n",
    "        loss.backward()  # Обратное распространение ошибки\n",
    "\n",
    "        # Клиппинг градиентов\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()  # Обновляем параметры\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        n_inter += 1\n",
    "        if n_inter % 500 == 0:\n",
    "            callback(np.mean(losses))\n",
    "            losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTAa7iZwJ7JK"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        src = batch[:, :-1].to(device)\n",
    "        trg = batch[:, 1:].to(device)\n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            logits = model(src)\n",
    "            loss = criterion(logits.transpose(1, 2), trg)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mz71eFiJ2HsJ",
    "outputId": "7728f162-73fa-4942-d104-df6dbf0fa922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.988071646009173"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xAp9BCs3j09"
   },
   "source": [
    "Получите `loss < 5.0` на тестовой выборке. \n",
    "\n",
    "Если модель обучается слишком быстро до значений <1.0 вы что-то напутали с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u53s8iAaHvkx"
   },
   "outputs": [],
   "source": [
    "def callback(train_loss):\n",
    "    eval_loss = eval_model(model)\n",
    "    model.train()\n",
    "    print(f'Epoch: {epoch+1:02} | train_loss = {train_loss:.5f}, eval_loss = {eval_loss:.5f}')\n",
    "\n",
    "for epoch in trange(5):\n",
    "    train_loss = train_epoch(model, callback)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Параметры модели\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 512\n",
    "num_layers = 2\n",
    "\n",
    "# Инициализация модели, оптимизатора и функции потерь\n",
    "model = RnnGenerator(vocab_size, embed_dim, num_layers).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_token_idx)\n",
    "\n",
    "# Тренировка модели\n",
    "for epoch in trange(5):\n",
    "    train_epoch(model, callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM0v9e_VhjiC"
   },
   "source": [
    "# Генерация текста (5 баллов) \n",
    "\n",
    "Реализуйте функцию, которая продолжает текст.\n",
    "1.   Переведите строчку в токены\n",
    "2.   Реализуйте код который предсказывает вероятность следующей буквы\n",
    "3.   Семплируйте следующую букву\n",
    "4.   Повторяйте пункты 2-3 в цикле\n",
    "5.   Преобразуйте токены в строчку\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrWzAch9vuYd"
   },
   "outputs": [],
   "source": [
    "def continues_sentence(sentence, model, max_len = 30):\n",
    "    model.eval()    \n",
    "    tokens = list(encode(sentence.lower()))\n",
    "    for _ in range(max_len):\n",
    "        input_ids = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids)\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        probabilities = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "        next_token = torch.multinomial(probabilities, num_samples=1).item()\n",
    "        tokens.append(next_token)\n",
    "        if next_token == sep_token_idx:\n",
    "            break    \n",
    "    \n",
    "    return decoder.decode(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZD6xO9_0w4L6",
    "outputId": "0149d991-c440-4f16-d16e-7664fb7e239a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'я помню чудное мгновенье, в руки напомнились! маркизов усмехнулся и даму до чаю : не один этого дома нет, даже заревывал восм приятелю'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Я помню чудное мгновенье\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wMybLhDd4Pc2",
    "outputId": "9035a278-b41f-4d63-91df-f8344e7c4903"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'мои дядя самых честных правил, позвольте...... между тем я имеющии бедныи лист на руках лета... всю тем дрожка, он расхо'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Мой дядя самых честных правил,\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "U3bDy6mk_8Jm",
    "outputId": "647cd236-d633-4c4a-e25c-a530ce3e1b09"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'четыре года потратил деонардо на тот день вечер, и первыи былев сам выскочил из мещан и кстати разговился им с деньгами. бецкая женщина'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Четыре года потратил Деонардо на\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "FBiAtkLAADx2",
    "outputId": "4e2e8e8b-40a7-4462-82cd-3d7988079dc0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'если сила плохих людеи в том, что они вместе, то хорошим людям, чтобы стать силои, надо показывать любо, у нашеи обязанности и странности отречения человека ; в числе его, оно проитис налевые, - в том'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_sentence(\"Если сила плохих людей в том, что они вместе, то хорошим людям, чтобы стать силой, надо\", model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
