{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В задании вам понадобится собрать генеративную модлель для языка\n",
    "\n",
    "---\n",
    "\n",
    "# LSTM (7 баллов)\n",
    "\n",
    "В данной части нужно реализовать модель с ипользованием LSTM"
   ],
   "id": "c582c5700987614d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T07:50:54.981818Z",
     "start_time": "2024-10-21T07:50:53.906060Z"
    }
   },
   "source": "!pip install --quiet sentencepiece datasets transformers",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:50:59.575542Z",
     "start_time": "2024-10-21T07:50:57.985846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_maker import DatasetMaker, collate_batch\n",
    "from data_generator import DataGenerator"
   ],
   "id": "1ced866b9f290664",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:51:02.602764Z",
     "start_time": "2024-10-21T07:51:02.597252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "cfd7499b45fc92ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ниже вам нужно реализовать модель, которая по началу последовательности предсказывает следующий токен.\n",
    "*   Модель получает на вход последовательность токенов, прогоняет её через LSTM и выдает вероятности следующего токена.  \n",
    "*   Используйте LSTM из pytorch\n",
    "*   Не забудьте про `batch_first`"
   ],
   "id": "4a870cea923d082b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:51:07.024318Z",
     "start_time": "2024-10-21T07:51:07.022236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DIRECTORY = './data/books_txt'  \n",
    "VOCAB_PATH = './data/vocab.txt'\n",
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "OFFSET = MAX_SEQ_LEN // 2\n",
    "TEST_SIZE = 0.03"
   ],
   "id": "674f291a7a32cc6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:09.555288Z",
     "start_time": "2024-10-21T07:51:10.715212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_maker = DatasetMaker(directory=DIRECTORY, test_size=TEST_SIZE, vocab_path=VOCAB_PATH, max_seq_len=MAX_SEQ_LEN, batch_size=BATCH_SIZE, offset=OFFSET, create_test_segments=True)\n",
    "train_dataloader = DataLoader(dataset_maker, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(dataset_maker.segments_test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
   ],
   "id": "3eef7ac2dcfce4ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:36.329985Z",
     "start_time": "2024-10-21T07:52:36.325930Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_maker.tokenizer.vocab_size",
   "id": "7f5657c713819b71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:39.695625Z",
     "start_time": "2024-10-21T07:52:39.692919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "EMBEDDING_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "PAD_TOKEN_IDX = 0\n",
    "SAVE_PATH = './saved_models'"
   ],
   "id": "993846b5a5c97367",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:43.583731Z",
     "start_time": "2024-10-21T07:52:43.517861Z"
    }
   },
   "cell_type": "code",
   "source": "model = DataGenerator(vocab_size=dataset_maker.tokenizer.vocab_size, test_dataloader=test_dataloader, embed_dim=EMBEDDING_DIM, num_layers=NUM_LAYERS, pad_token_idx=PAD_TOKEN_IDX, device=device)",
   "id": "d082f610ee5de3c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Реализуйте обучение модели:\n",
    "*  Не забудьте сдвинуть src и trg относительно друг друга.\n",
    "*  Не забудьте про `clip_grad_norm_`\n",
    "*  Данных очень много, для отладки лучше проходить только часть данных иначе этоха будет очень длинной\n",
    "\n",
    "Получите `loss < 5.0` на тестовой выборке. \n",
    "\n",
    "Если модель обучается слишком быстро до значений <1.0 вы что-то напутали с данными."
   ],
   "id": "d7a66566bbf70a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-16T13:57:09.435413Z"
    }
   },
   "cell_type": "code",
   "source": "model.train_loop(epochs=100, train_dataloader=train_dataloader, lr=LEARNING_RATE, save_path=SAVE_PATH)",
   "id": "48008dd5a1e7e71a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 61%|██████    | 10335/17049 [2:20:02<1:29:19,  1.25it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Генерация текста (5 баллов) \n",
    "\n",
    "Реализуйте функцию, которая продолжает текст.\n",
    "1.   Переведите строчку в токены\n",
    "2.   Реализуйте код который предсказывает вероятность следующей буквы\n",
    "3.   Семплируйте следующую букву\n",
    "4.   Повторяйте пункты 2-3 в цикле\n",
    "5.   Преобразуйте токены в строчку"
   ],
   "id": "b98449486183cad3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:48.710637Z",
     "start_time": "2024-10-21T07:52:48.652048Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_model(SAVE_PATH)",
   "id": "af9db28e5d5e5baf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from model_epoch_50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanzolin/Documents/itmo-magistracy/dl-practice/data_generator.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.__device)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:52:54.220464Z",
     "start_time": "2024-10-21T07:52:54.079219Z"
    }
   },
   "cell_type": "code",
   "source": "model.continues_sentence(\"Я помню чудное мгновенье\", dataset_maker.tokenizer)",
   "id": "ed0ddfb71bb441b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я помню чудное мгновенье, когда я был в восторге, когда я был счастлив, и я, как будто я, не мог не видеть, что я не могу быть'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:53:54.855126Z",
     "start_time": "2024-10-21T07:53:54.700850Z"
    }
   },
   "cell_type": "code",
   "source": "model.continues_sentence(\"Мой дядя самых честных правил,\", dataset_maker.tokenizer)",
   "id": "e36efc73d0f23a89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мои дядя самых честных правил, и я, как и я, не знаю, что я такое. я не знаю, что я говорю, но я не могу не верить, что'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:56:01.216930Z",
     "start_time": "2024-10-21T07:56:01.079328Z"
    }
   },
   "cell_type": "code",
   "source": "model.continues_sentence(\"Четыре года потратил Деонардо на\", dataset_maker.tokenizer)",
   "id": "298be8a5b580b0e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'четыре года потратил деонардо на себя. - - - - - - - - - - - - - - - - - - - - - - - - - - - -'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T07:55:26.369476Z",
     "start_time": "2024-10-21T07:55:26.204504Z"
    }
   },
   "cell_type": "code",
   "source": "model.continues_sentence(\"Если сила плохих людей в том, что они вместе, то хорошим людям, чтобы стать силой, надо\", dataset_maker.tokenizer)",
   "id": "8f970388454e893d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если сила плохих людеи в том, что они вместе, то хорошим людям, чтобы стать силои, надо было бы, чтобы они были так же счастливы, как и они, и потому не могли бы быть счастливыми. и потому, что они не'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
